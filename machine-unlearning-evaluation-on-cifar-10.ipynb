{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":56167,"databundleVersionId":6535361,"sourceType":"competition"},{"sourceId":147860469,"sourceType":"kernelVersion"}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport requests\nfrom copy import deepcopy\nfrom typing import Callable\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\nfrom sklearn import linear_model, model_selection\nfrom sklearn.metrics import make_scorer, accuracy_score\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader, Subset, random_split\n\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torchvision.models import resnet18\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Running on device:\", DEVICE.upper())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T11:14:50.123878Z","iopub.execute_input":"2023-12-07T11:14:50.124582Z","iopub.status.idle":"2023-12-07T11:14:53.997002Z","shell.execute_reply.started":"2023-12-07T11:14:50.124529Z","shell.execute_reply":"2023-12-07T11:14:53.996082Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Running on device: CUDA\n","output_type":"stream"}]},{"cell_type":"code","source":"def accuracy(net, loader):\n    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n    correct = 0\n    total = 0\n    for inputs, targets in loader:\n        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n        outputs = net(inputs)\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n    return correct / total\n\n\ndef compute_outputs(net, loader):\n    \"\"\"Auxiliary function to compute the logits for all datapoints.\n    Does not shuffle the data, regardless of the loader.\n    \"\"\"\n\n    # Make sure loader does not shuffle the data\n    if isinstance(loader.sampler, torch.utils.data.sampler.RandomSampler):\n        loader = DataLoader(\n            loader.dataset, \n            batch_size=loader.batch_size, \n            shuffle=False, \n            num_workers=loader.num_workers)\n    \n    all_outputs = []\n    \n    for inputs, targets in loader:\n        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n\n        logits = net(inputs).detach().cpu().numpy() # (batch_size, num_classes)\n        \n        all_outputs.append(logits)\n        \n    return np.concatenate(all_outputs) # (len(loader.dataset), num_classes)\n\n\ndef false_positive_rate(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"Computes the false positive rate (FPR).\"\"\"\n    fp = np.sum(np.logical_and((y_pred == 1), (y_true == 0)))\n    n = np.sum(y_true == 0)\n    return fp / n\n\n\ndef false_negative_rate(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"Computes the false negative rate (FNR).\"\"\"\n    fn = np.sum(np.logical_and((y_pred == 0), (y_true == 1)))\n    p = np.sum(y_true == 1)\n    return fn / p\n\n\n# The SCORING dictionary is used by sklearn's `cross_validate` function so that\n# we record the FPR and FNR metrics of interest when doing cross validation\nSCORING = {\n    'false_positive_rate': make_scorer(false_positive_rate),\n    'false_negative_rate': make_scorer(false_negative_rate)\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.001199Z","iopub.execute_input":"2023-12-07T11:14:54.001612Z","iopub.status.idle":"2023-12-07T11:14:54.013369Z","shell.execute_reply.started":"2023-12-07T11:14:54.001582Z","shell.execute_reply":"2023-12-07T11:14:54.012493Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def cross_entropy_f(x):\n    # To ensure this function doesn't fail due to nans, find\n    # all-nan rows in x and substitude them with all-zeros.\n    x[np.all(np.isnan(x), axis=-1)] = np.zeros(x.shape[-1])\n    \n    pred = torch.tensor(np.nanargmax(x, axis = -1))\n    x = torch.tensor(x)\n\n    fn = nn.CrossEntropyLoss(reduction=\"none\")\n    \n    return fn(x, pred).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.014604Z","iopub.execute_input":"2023-12-07T11:14:54.015395Z","iopub.status.idle":"2023-12-07T11:14:54.037182Z","shell.execute_reply.started":"2023-12-07T11:14:54.015363Z","shell.execute_reply":"2023-12-07T11:14:54.036300Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def logistic_regression_attack(\n        outputs_U, outputs_R, n_splits=2, random_state=0):\n    \"\"\"Computes cross-validation score of a membership inference attack.\n\n    Args:\n      outputs_U: numpy array of shape (N)\n      outputs_R: numpy array of shape (N)\n      n_splits: int\n        number of splits to use in the cross-validation.\n    Returns:\n      fpr, fnr : float * float\n    \"\"\"\n    assert len(outputs_U) == len(outputs_R)\n    \n    samples = np.concatenate((outputs_R, outputs_U)).reshape((-1, 1))\n    labels = np.array([0] * len(outputs_R) + [1] * len(outputs_U))\n\n    attack_model = linear_model.LogisticRegression()\n    cv = model_selection.StratifiedShuffleSplit(\n        n_splits=n_splits, random_state=random_state\n    )\n    scores =  model_selection.cross_validate(\n        attack_model, samples, labels, cv=cv, scoring=SCORING)\n    \n    fpr = np.mean(scores[\"test_false_positive_rate\"])\n    fnr = np.mean(scores[\"test_false_negative_rate\"])\n    \n    return fpr, fnr\n\n\ndef best_threshold_attack(\n        outputs_U: np.ndarray, \n        outputs_R: np.ndarray, \n        random_state: int = 0\n    ) -> tuple[list[float], list[float]]:\n    \"\"\"Computes FPRs and FNRs for an attack that simply splits into \n    predicted positives and predited negatives based on any possible \n    single threshold.\n\n    Args:\n      outputs_U: numpy array of shape (N)\n      outputs_R: numpy array of shape (N)\n    Returns:\n      fpr, fnr : list[float] * list[float]\n    \"\"\"\n    assert len(outputs_U) == len(outputs_R)\n    \n    samples = np.concatenate((outputs_R, outputs_U))\n    labels = np.array([0] * len(outputs_R) + [1] * len(outputs_U))\n\n    N = len(outputs_U)\n    \n    fprs, fnrs = [], []\n    for thresh in sorted(list(samples.squeeze())):\n        ypred = (samples > thresh).astype(\"int\")\n        fprs.append(false_positive_rate(labels, ypred))\n        fnrs.append(false_negative_rate(labels, ypred))\n    \n    return fprs, fnrs","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.038382Z","iopub.execute_input":"2023-12-07T11:14:54.038997Z","iopub.status.idle":"2023-12-07T11:14:54.052038Z","shell.execute_reply.started":"2023-12-07T11:14:54.038964Z","shell.execute_reply":"2023-12-07T11:14:54.051187Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def compute_epsilon_s(fpr: list[float], fnr: list[float], delta: float) -> float:\n    \"\"\"Computes the privacy degree (epsilon) of a particular forget set example, \n    given the FPRs and FNRs resulting from various attacks.\n    \n    The smaller epsilon is, the better the unlearning is.\n    \n    Args:\n      fpr: list[float] of length m = num attacks. The FPRs for a particular example. \n      fnr: list[float] of length m = num attacks. The FNRs for a particular example.\n      delta: float\n    Returns:\n      epsilon: float corresponding to the privacy degree of the particular example.\n    \"\"\"\n    assert len(fpr) == len(fnr)\n    \n    per_attack_epsilon = [0.]\n    for fpr_i, fnr_i in zip(fpr, fnr):\n        if fpr_i == 0 and fnr_i == 0:\n            per_attack_epsilon.append(np.inf)\n        elif fpr_i == 0 or fnr_i == 0:\n            pass # discard attack\n        else:\n            with np.errstate(invalid='ignore'):\n                epsilon1 = np.log(1. - delta - fpr_i) - np.log(fnr_i)\n                epsilon2 = np.log(1. - delta - fnr_i) - np.log(fpr_i)\n            if np.isnan(epsilon1) and np.isnan(epsilon2):\n                per_attack_epsilon.append(np.inf)\n            else:\n                per_attack_epsilon.append(np.nanmax([epsilon1, epsilon2]))\n            \n    return np.nanmax(per_attack_epsilon)\n\n\ndef bin_index_fn(\n        epsilons: np.ndarray, \n        bin_width: float = 0.5, \n        B: int = 13\n        ) -> np.ndarray:\n    \"\"\"The bin index function.\"\"\"\n    bins = np.arange(0, B) * bin_width\n    return np.digitize(epsilons, bins)\n\n\ndef F(epsilons: np.ndarray) -> float:\n    \"\"\"Computes the forgetting quality given the privacy degrees \n    of the forget set examples.\n    \"\"\"\n    ns = bin_index_fn(epsilons)\n    hs = 2. / 2 ** ns\n    return np.mean(hs)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.054295Z","iopub.execute_input":"2023-12-07T11:14:54.054582Z","iopub.status.idle":"2023-12-07T11:14:54.066041Z","shell.execute_reply.started":"2023-12-07T11:14:54.054558Z","shell.execute_reply":"2023-12-07T11:14:54.065181Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def forgetting_quality(\n        outputs_U: np.ndarray, # (N, S)\n        outputs_R: np.ndarray, # (N, S)\n        attacks: list[Callable] = [logistic_regression_attack],\n        delta: float = 0.01\n    ):\n    \"\"\"\n    Both `outputs_U` and `outputs_R` are of numpy arrays of ndim 2:\n    * 1st dimension coresponds to the number of samples obtained from the \n      distribution of each model (N=512 in the case of the competition's leaderboard) \n    * 2nd dimension corresponds to the number of samples in the forget set (S).\n    \"\"\"\n    \n    # N = number of model samples\n    # S = number of forget samples\n    N, S = outputs_U.shape\n    \n    assert outputs_U.shape == outputs_R.shape, \\\n        \"unlearn and retrain outputs need to be of the same shape\"\n    \n    epsilons = []\n    pbar = tqdm(range(S))\n    for sample_id in pbar:\n        pbar.set_description(\"Computing F...\")\n        \n        sample_fprs, sample_fnrs = [], []\n        \n        for attack in attacks: \n            uls = outputs_U[:, sample_id]\n            rls = outputs_R[:, sample_id]\n            \n            fpr, fnr = attack(uls, rls)\n            \n            if isinstance(fpr, list):\n                sample_fprs.extend(fpr)\n                sample_fnrs.extend(fnr)\n            else:\n                sample_fprs.append(fpr)\n                sample_fnrs.append(fnr)\n        \n        sample_epsilon = compute_epsilon_s(sample_fprs, sample_fnrs, delta=delta)\n        epsilons.append(sample_epsilon)\n        \n    return F(np.array(epsilons))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.067018Z","iopub.execute_input":"2023-12-07T11:14:54.067274Z","iopub.status.idle":"2023-12-07T11:14:54.080021Z","shell.execute_reply.started":"2023-12-07T11:14:54.067252Z","shell.execute_reply":"2023-12-07T11:14:54.079284Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def score_unlearning_algorithm(\n        data_loaders: dict, \n        pretrained_models: dict, \n        unlearning: Callable, \n        n: int = 10,\n        delta: float = 0.01,\n        f: Callable = cross_entropy_f,\n        attacks: list[Callable] = [best_threshold_attack, logistic_regression_attack]\n        ) -> dict:\n    \n    # n=512 in the case of unlearn and n=1 in the\n    # case of retrain, since we are only provided with one retrained model here\n\n    retain_loader = data_loaders[\"retain\"]\n    forget_loader = data_loaders[\"forget\"]\n    val_loader = data_loaders[\"validation\"]\n    test_loader = data_loaders[\"testing\"]\n\n    original_model = pretrained_models[\"original\"]\n    rt_model = pretrained_models[\"retrained\"]\n\n    outputs_U = []\n    retain_accuracy = []\n    test_accuracy = []\n    forget_accuracy = []\n\n    pbar = tqdm(range(n))\n    for i in pbar:\n        # unlearned model\n        u_model = deepcopy(original_model)\n        # Execute the unlearing routine. This might take a few minutes.\n        # If run on colab, be sure to be running it on  an instance with GPUs\n\n        pbar.set_description(f\"Unlearning...\")\n        u_model = unlearning(u_model, retain_loader, forget_loader, val_loader)\n\n        outputs_Ui = compute_outputs(u_model, forget_loader) \n        # The shape of outputs_Ui is (len(forget_loader.dataset), 10)\n        # which for every datapoint is being cast to a scalar using the funtion f\n        outputs_U.append( f(outputs_Ui) )\n\n        pbar.set_description(f\"Computing retain accuracy...\")\n        retain_accuracy.append(accuracy(u_model, retain_loader))\n\n        pbar.set_description(f\"Computing test accuracy...\")\n        test_accuracy.append(accuracy(u_model, test_loader))\n\n        pbar.set_description(f\"Computing forget accuracy...\")\n        forget_accuracy.append(accuracy(u_model, forget_loader))\n\n\n    outputs_U = np.array(outputs_U) # (n, len(forget_loader.dataset))\n\n    assert outputs_U.shape == (n, len(forget_loader.dataset)),\\\n        \"Wrong shape for outputs_U. Should be (num_model_samples, num_forget_datapoints).\"\n\n    RAR = accuracy(rt_model, retain_loader)\n    TAR = accuracy(rt_model, test_loader)\n    FAR = accuracy(rt_model, forget_loader)\n\n    RAU = np.mean(retain_accuracy)\n    TAU = np.mean(test_accuracy)\n    FAU = np.mean(forget_accuracy)\n\n    RA_ratio = RAU / RAR\n    TA_ratio = TAU / TAR\n\n    # need to fake this a little because we only have one retrain model\n    scale = np.std(outputs_U) / 10.\n    outputs_Ri = compute_outputs(rt_model, forget_loader) #(len(forget_loader.dataset), 10) \n    outputs_Ri = np.expand_dims(outputs_Ri, axis=0)\n    outputs_Ri = np.random.normal(\n        loc=outputs_Ri, scale=scale, size=(n, *outputs_Ri.shape[-2:]))\n    \n    outputs_R = np.array([ f( oRi ) for oRi in outputs_Ri ])\n\n    np.save(\"outputs_U.npy\", outputs_U)\n    np.save(\"outputs_R.npy\", outputs_R)\n    \n    f = forgetting_quality(\n        outputs_U, \n        outputs_R,\n        attacks=attacks,\n        delta=delta)\n\n    return {\n        \"total_score\": f * RA_ratio * TA_ratio,\n        \"F\": f,\n        \"unlearn_retain_accuracy\": RAU,\n        \"unlearn_test_accuracy\": TAU, \n        \"unlearn_forget_accuracy\": FAU,\n        \"retrain_retain_accuracy\": RAR,\n        \"retrain_test_accuracy\": TAR, \n        \"retrain_forget_accuracy\": FAR,\n        \"retrain_outputs\": outputs_R,\n        \"unlearn_outputs\": outputs_U\n    }","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.081316Z","iopub.execute_input":"2023-12-07T11:14:54.081591Z","iopub.status.idle":"2023-12-07T11:14:54.098319Z","shell.execute_reply.started":"2023-12-07T11:14:54.081568Z","shell.execute_reply":"2023-12-07T11:14:54.097424Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def unlearning(net, *args, **kwargs): \n    \"\"\"A placeholder prefect unlearning function, which returns \n    the retrained model. Note there is no randomness in this\"\"\"\n    return deepcopy(pretrained_models[\"retrained\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.099454Z","iopub.execute_input":"2023-12-07T11:14:54.099776Z","iopub.status.idle":"2023-12-07T11:14:54.110752Z","shell.execute_reply.started":"2023-12-07T11:14:54.099752Z","shell.execute_reply":"2023-12-07T11:14:54.109895Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from load_cifar_script import get_cifar10_data, get_cifar10_pretrained_models\n\ndata_loaders = get_cifar10_data()\npretrained_models = get_cifar10_pretrained_models(device=DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:14:54.111859Z","iopub.execute_input":"2023-12-07T11:14:54.112153Z","iopub.status.idle":"2023-12-07T11:15:15.492262Z","shell.execute_reply.started":"2023-12-07T11:14:54.112129Z","shell.execute_reply":"2023-12-07T11:15:15.491182Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:08<00:00, 20603477.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"ret = score_unlearning_algorithm(data_loaders, pretrained_models, unlearning)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:15:15.493739Z","iopub.execute_input":"2023-12-07T11:15:15.494120Z","iopub.status.idle":"2023-12-07T11:17:46.973013Z","shell.execute_reply.started":"2023-12-07T11:15:15.494090Z","shell.execute_reply":"2023-12-07T11:17:46.972013Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a12833e74124f779f2440990039a31d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"822b970153b140c9a5b89dd9f637b9f1"}},"metadata":{}}]},{"cell_type":"code","source":"ret","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:17:46.974647Z","iopub.execute_input":"2023-12-07T11:17:46.975086Z","iopub.status.idle":"2023-12-07T11:17:46.984900Z","shell.execute_reply.started":"2023-12-07T11:17:46.975046Z","shell.execute_reply":"2023-12-07T11:17:46.984002Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'total_score': 0.9534113769531251,\n 'F': 0.953411376953125,\n 'unlearn_retain_accuracy': 0.9952666666666665,\n 'unlearn_test_accuracy': 0.8796000000000002,\n 'unlearn_forget_accuracy': 0.882,\n 'retrain_retain_accuracy': 0.9952666666666666,\n 'retrain_test_accuracy': 0.8796,\n 'retrain_forget_accuracy': 0.882,\n 'retrain_outputs': array([[3.84890480e-01, 6.92073349e-03, 5.48717234e-05, ...,\n         1.39935099e-01, 4.61490691e-01, 2.20999630e-03],\n        [3.84641802e-01, 6.88673248e-03, 5.39030134e-05, ...,\n         1.41328284e-01, 4.69872031e-01, 2.18830036e-03],\n        [3.87948224e-01, 6.65291905e-03, 5.46578095e-05, ...,\n         1.38929142e-01, 4.65964080e-01, 2.17632991e-03],\n        ...,\n        [3.68025269e-01, 6.96302497e-03, 5.42618523e-05, ...,\n         1.40273922e-01, 4.62792214e-01, 2.16835909e-03],\n        [3.83553125e-01, 6.74124149e-03, 5.43503650e-05, ...,\n         1.36329847e-01, 4.57079297e-01, 2.15090254e-03],\n        [3.84942865e-01, 6.58484927e-03, 5.50024655e-05, ...,\n         1.44174046e-01, 4.80391963e-01, 2.14436310e-03]]),\n 'unlearn_outputs': array([[3.8563216e-01, 6.8271230e-03, 5.4477161e-05, ..., 1.4155446e-01,\n         4.6083200e-01, 2.1786781e-03],\n        [3.8563216e-01, 6.8271230e-03, 5.4477161e-05, ..., 1.4155446e-01,\n         4.6083200e-01, 2.1786781e-03],\n        [3.8563216e-01, 6.8271230e-03, 5.4477161e-05, ..., 1.4155446e-01,\n         4.6083200e-01, 2.1786781e-03],\n        ...,\n        [3.8563216e-01, 6.8271230e-03, 5.4477161e-05, ..., 1.4155446e-01,\n         4.6083200e-01, 2.1786781e-03],\n        [3.8563216e-01, 6.8271230e-03, 5.4477161e-05, ..., 1.4155446e-01,\n         4.6083200e-01, 2.1786781e-03],\n        [3.8563216e-01, 6.8271230e-03, 5.4477161e-05, ..., 1.4155446e-01,\n         4.6083200e-01, 2.1786781e-03]], dtype=float32)}"},"metadata":{}}]},{"cell_type":"code","source":"udata = ret[\"unlearn_outputs\"][:,0]\nrdata = ret[\"retrain_outputs\"][:,0]\ndata = np.array([udata, rdata])\n\nbins = np.arange(np.min(data), np.max(data) + 0.1, 0.1)\n\nplt.hist(udata, bins=bins, alpha=0.7, label=\"Unlearned\")\nplt.hist(rdata, bins=bins, alpha=0.7, label=\"Retrained\")\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:17:46.986014Z","iopub.execute_input":"2023-12-07T11:17:46.986300Z","iopub.status.idle":"2023-12-07T11:17:47.267475Z","shell.execute_reply.started":"2023-12-07T11:17:46.986276Z","shell.execute_reply":"2023-12-07T11:17:47.266462Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}